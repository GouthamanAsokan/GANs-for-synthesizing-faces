{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIabOSPhYgTD",
        "colab_type": "text"
      },
      "source": [
        "# Generating High Rez GAN Faces with Google CoLab\n",
        "\n",
        "This notebook demonstrates how to run [NVidia StyleGAN](https://github.com/NVlabs/stylegan) inside of a Google CoLab notebook.  I suggest you use this to generate GAN faces from a pretrained model.  If you try to train your own, you will run into compute limitations of Google CoLab.\n",
        "\n",
        "Make sure to run this code on a GPU instance.  GPU is assumed.\n",
        "\n",
        "This is from my [class on deep learning](  https://www.youtube.com/watch?v=EQ38k6z2aks&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
        "\n",
        "[Jeff Heaton](https://www.heatonresearch.com/)\n",
        "\n",
        "# Instructions\n",
        "\n",
        "First, map your G-Drive, this is where your GANs will be written to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv7PBBU7kOkD",
        "colab_type": "code",
        "outputId": "aa2b02bc-545d-4a26-c194-665db41a662f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX4LsOo_YstE",
        "colab_type": "text"
      },
      "source": [
        "Next, clone Stylegan from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjDcs9Wvhk_6",
        "colab_type": "code",
        "outputId": "c1f87f7f-f33a-4596-f376-b9bdb238115e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGqVIl8Y1m1",
        "colab_type": "text"
      },
      "source": [
        "Verify that Stylegan has been cloned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQMXLBNjoV5",
        "colab_type": "code",
        "outputId": "d563d8f5-4488-43a9-c610-a9501563fe2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!ls /content/stylegan/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.py\t     LICENSE.txt\t    run_metrics.py\n",
            "dataset_tool.py      metrics\t\t    stylegan-teaser.png\n",
            "dnnlib\t\t     pretrained_example.py  training\n",
            "generate_figures.py  README.md\t\t    train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zARjPp4rY6vc",
        "colab_type": "text"
      },
      "source": [
        "Add the Stylegan folder to Python so that you can import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaFXI2RMhmly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan\")\n",
        "\n",
        "import dnnlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxmjqpxdZFkj",
        "colab_type": "text"
      },
      "source": [
        "The code below is baed on code from NVidia.  This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfN_qgXVi2PU",
        "colab_type": "code",
        "outputId": "8881d9c1-8704-4709-dbf9-b7d4b1332181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Minimal script for generating an image using pre-trained StyleGAN generator.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "\n",
        "def main():\n",
        "    # Initialize TensorFlow.\n",
        "    tflib.init_tf()\n",
        "\n",
        "    # Load pre-trained network.\n",
        "    url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
        "    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "        _G, _D, Gs = pickle.load(f)\n",
        "        # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n",
        "        # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n",
        "        # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n",
        "\n",
        "    # Print network details.\n",
        "    Gs.print_layers()\n",
        "\n",
        "    # Pick latent vector.\n",
        "    rnd = np.random.RandomState()\n",
        "    \n",
        "\n",
        "    latents = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "    # Generate image.\n",
        "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "\n",
        "    # Save image.\n",
        "    os.makedirs(config.result_dir, exist_ok=True)\n",
        "    png_filename = os.path.join(config.result_dir, f'/content/drive/My Drive/GAN/example3.png')\n",
        "    PIL.Image.fromarray(images[0], 'RGB').save(png_filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Gs                              Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "lod                             -         ()                   -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "G_mapping/latents_in            -         (?, 512)             -               \n",
            "G_mapping/labels_in             -         (?, 0)               -               \n",
            "G_mapping/PixelNorm             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "G_mapping/dlatents_out          -         (?, 18, 512)         -               \n",
            "Truncation                      -         (?, 18, 512)         -               \n",
            "G_synthesis/dlatents_in         -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           534528    (?, 512, 4, 4)       (512,)          \n",
            "G_synthesis/4x4/Conv            2885632   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod8          1539      (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod7          1539      (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D           -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/Grow_lod7           -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/16x16/Conv0_up      2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod6          1539      (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_1         -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/Grow_lod6           -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/32x32/Conv0_up      2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod5          1539      (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_2         -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/Grow_lod5           -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/64x64/Conv0_up      1442816   (?, 256, 64, 64)     (3, 3, 512, 256)\n",
            "G_synthesis/64x64/Conv1         852992    (?, 256, 64, 64)     (3, 3, 256, 256)\n",
            "G_synthesis/ToRGB_lod4          771       (?, 3, 64, 64)       (1, 1, 256, 3)  \n",
            "G_synthesis/Upscale2D_3         -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/Grow_lod4           -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/128x128/Conv0_up    426496    (?, 128, 128, 128)   (3, 3, 256, 128)\n",
            "G_synthesis/128x128/Conv1       279040    (?, 128, 128, 128)   (3, 3, 128, 128)\n",
            "G_synthesis/ToRGB_lod3          387       (?, 3, 128, 128)     (1, 1, 128, 3)  \n",
            "G_synthesis/Upscale2D_4         -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/Grow_lod3           -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/256x256/Conv0_up    139520    (?, 64, 256, 256)    (3, 3, 128, 64) \n",
            "G_synthesis/256x256/Conv1       102656    (?, 64, 256, 256)    (3, 3, 64, 64)  \n",
            "G_synthesis/ToRGB_lod2          195       (?, 3, 256, 256)     (1, 1, 64, 3)   \n",
            "G_synthesis/Upscale2D_5         -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/Grow_lod2           -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/512x512/Conv0_up    51328     (?, 32, 512, 512)    (3, 3, 64, 32)  \n",
            "G_synthesis/512x512/Conv1       42112     (?, 32, 512, 512)    (3, 3, 32, 32)  \n",
            "G_synthesis/ToRGB_lod1          99        (?, 3, 512, 512)     (1, 1, 32, 3)   \n",
            "G_synthesis/Upscale2D_6         -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/Grow_lod1           -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/1024x1024/Conv0_up  21056     (?, 16, 1024, 1024)  (3, 3, 32, 16)  \n",
            "G_synthesis/1024x1024/Conv1     18752     (?, 16, 1024, 1024)  (3, 3, 16, 16)  \n",
            "G_synthesis/ToRGB_lod0          51        (?, 3, 1024, 1024)   (1, 1, 16, 3)   \n",
            "G_synthesis/Upscale2D_7         -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/Grow_lod0           -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/images_out          -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/lod                 -         ()                   -               \n",
            "G_synthesis/noise0              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise1              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise2              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise3              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise4              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise5              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise6              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise7              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise8              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise9              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise10             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise11             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise12             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise13             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise14             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise15             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise16             -         (1, 1, 1024, 1024)   -               \n",
            "G_synthesis/noise17             -         (1, 1, 1024, 1024)   -               \n",
            "images_out                      -         (?, 3, 1024, 1024)   -               \n",
            "---                             ---       ---                  ---             \n",
            "Total                           26219627                                       \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqJGX1Gj_fn",
        "colab_type": "code",
        "outputId": "26c9c483-f052-4f86-82dc-19aed8ee9f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'#10 Blindness Detection'\n",
            "'#16 HDFC Hiring'\n",
            " 5-celebrity-faces-dataset.zip\n",
            "'AmExpert Hackathon'\n",
            " ANPD2\n",
            " Bank_loan_prediction\n",
            " bert-tfhub\n",
            " car.jpg\n",
            " coins.jpg\n",
            "'Colab Notebooks'\n",
            " Cropped_Images\n",
            " Cropped_Images0.jpg\n",
            " Cropped_Images100.jpg\n",
            " Cropped_Images101.jpg\n",
            " Cropped_Images102.jpg\n",
            " Cropped_Images103.jpg\n",
            " Cropped_Images104.jpg\n",
            " Cropped_Images105.jpg\n",
            " Cropped_Images106.jpg\n",
            " Cropped_Images107.jpg\n",
            " Cropped_Images108.jpg\n",
            " Cropped_Images109.jpg\n",
            " Cropped_Images10.jpg\n",
            " Cropped_Images110.jpg\n",
            " Cropped_Images111.jpg\n",
            " Cropped_Images112.jpg\n",
            " Cropped_Images113.jpg\n",
            " Cropped_Images114.jpg\n",
            " Cropped_Images115.jpg\n",
            " Cropped_Images116.jpg\n",
            " Cropped_Images117.jpg\n",
            " Cropped_Images118.jpg\n",
            " Cropped_Images119.jpg\n",
            " Cropped_Images11.jpg\n",
            " Cropped_Images120.jpg\n",
            " Cropped_Images121.jpg\n",
            " Cropped_Images122.jpg\n",
            " Cropped_Images123.jpg\n",
            " Cropped_Images124.jpg\n",
            " Cropped_Images125.jpg\n",
            " Cropped_Images126.jpg\n",
            " Cropped_Images127.jpg\n",
            " Cropped_Images128.jpg\n",
            " Cropped_Images129.jpg\n",
            " Cropped_Images12.jpg\n",
            " Cropped_Images130.jpg\n",
            " Cropped_Images131.jpg\n",
            " Cropped_Images132.jpg\n",
            " Cropped_Images133.jpg\n",
            " Cropped_Images134.jpg\n",
            " Cropped_Images135.jpg\n",
            " Cropped_Images136.jpg\n",
            " Cropped_Images137.jpg\n",
            " Cropped_Images138.jpg\n",
            " Cropped_Images139.jpg\n",
            " Cropped_Images13.jpg\n",
            " Cropped_Images140.jpg\n",
            " Cropped_Images141.jpg\n",
            " Cropped_Images14.jpg\n",
            " Cropped_Images15.jpg\n",
            " Cropped_Images16.jpg\n",
            " Cropped_Images17.jpg\n",
            " Cropped_Images18.jpg\n",
            " Cropped_Images19.jpg\n",
            " Cropped_Images1.jpg\n",
            " Cropped_Images20.jpg\n",
            " Cropped_Images21.jpg\n",
            " Cropped_Images22.jpg\n",
            " Cropped_Images23.jpg\n",
            " Cropped_Images24.jpg\n",
            " Cropped_Images25.jpg\n",
            " Cropped_Images26.jpg\n",
            " Cropped_Images27.jpg\n",
            " Cropped_Images28.jpg\n",
            " Cropped_Images29.jpg\n",
            " Cropped_Images2.jpg\n",
            " Cropped_Images30.jpg\n",
            " Cropped_Images31.jpg\n",
            " Cropped_Images32.jpg\n",
            " Cropped_Images33.jpg\n",
            " Cropped_Images34.jpg\n",
            " Cropped_Images35.jpg\n",
            " Cropped_Images36.jpg\n",
            " Cropped_Images37.jpg\n",
            " Cropped_Images38.jpg\n",
            " Cropped_Images39.jpg\n",
            " Cropped_Images3.jpg\n",
            " Cropped_Images40.jpg\n",
            " Cropped_Images41.jpg\n",
            " Cropped_Images42.jpg\n",
            " Cropped_Images43.jpg\n",
            " Cropped_Images44.jpg\n",
            " Cropped_Images45.jpg\n",
            " Cropped_Images46.jpg\n",
            " Cropped_Images47.jpg\n",
            " Cropped_Images49.jpg\n",
            " Cropped_Images50.jpg\n",
            " Cropped_Images51.jpg\n",
            " Cropped_Images52.jpg\n",
            " Cropped_Images53.jpg\n",
            " Cropped_Images54.jpg\n",
            " Cropped_Images55.jpg\n",
            " Cropped_Images56.jpg\n",
            " Cropped_Images57.jpg\n",
            " Cropped_Images58.jpg\n",
            " Cropped_Images59.jpg\n",
            " Cropped_Images5.jpg\n",
            " Cropped_Images60.jpg\n",
            " Cropped_Images61.jpg\n",
            " Cropped_Images62.jpg\n",
            " Cropped_Images63.jpg\n",
            " Cropped_Images64.jpg\n",
            " Cropped_Images65.jpg\n",
            " Cropped_Images66.jpg\n",
            " Cropped_Images67.jpg\n",
            " Cropped_Images68.jpg\n",
            " Cropped_Images69.jpg\n",
            " Cropped_Images6.jpg\n",
            " Cropped_Images70.jpg\n",
            " Cropped_Images71.jpg\n",
            " Cropped_Images72.jpg\n",
            " Cropped_Images73.jpg\n",
            " Cropped_Images74.jpg\n",
            " Cropped_Images75.jpg\n",
            " Cropped_Images76.jpg\n",
            " Cropped_Images77.jpg\n",
            " Cropped_Images78.jpg\n",
            " Cropped_Images79.jpg\n",
            " Cropped_Images7.jpg\n",
            " Cropped_Images80.jpg\n",
            " Cropped_Images81.jpg\n",
            " Cropped_Images82.jpg\n",
            " Cropped_Images83.jpg\n",
            " Cropped_Images84.jpg\n",
            " Cropped_Images85.jpg\n",
            " Cropped_Images86.jpg\n",
            " Cropped_Images87.jpg\n",
            " Cropped_Images88.jpg\n",
            " Cropped_Images89.jpg\n",
            " Cropped_Images8.jpg\n",
            " Cropped_Images90.jpg\n",
            " Cropped_Images91.jpg\n",
            " Cropped_Images92.jpg\n",
            " Cropped_Images93.jpg\n",
            " Cropped_Images94.jpg\n",
            " Cropped_Images95.jpg\n",
            " Cropped_Images96.jpg\n",
            " Cropped_Images97.jpg\n",
            " Cropped_Images98.jpg\n",
            " Cropped_Images99.jpg\n",
            " Cropped_Images9.jpg\n",
            " CUDA\n",
            " Custom_Object_Detector\n",
            " dancing.mp4\n",
            " Deep_Q\n",
            "'Dimensionality Reduction'\n",
            " eiffel2.jpg\n",
            " eiffel.jpg\n",
            " facenet_keras.h5\n",
            " Final_Results\n",
            " FTVR\n",
            " GAN\n",
            " GAN_Pix2pix_Model\n",
            "'Getting started.pdf'\n",
            " Gouthaman_Resume.pdf\n",
            " index.png\n",
            " JSON_Files\n",
            " Kaggle\n",
            " Knowledge_Graph\n",
            "'Language Translation'\n",
            " lookbook.tar\n",
            " MaskRCNN_Human\n",
            "'MNIST Digit Generator'\n",
            " multiple.jpeg\n",
            "'Neural Style Transfer'\n",
            "'Neural Style Transfer.pptx'\n",
            " OCR\n",
            " person.jpg\n",
            " Pix2Pix\n",
            " Pix2Pix_Model\n",
            " PongwithDQN\n",
            " puppy.png\n",
            "'Recommendation Engine'\n",
            " resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "'Toxic comment challenge'\n",
            "'ValueLabs Hackathon'\n",
            "'Video Classification'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}